<!DOCTYPE html>
<html lang="en"
      data-content_root="./"
      x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }"
      x-init="$watch('darkMode', val => localStorage.setItem('darkMode', val))"
      class="scroll-smooth"
      :class="{'dark': darkMode === 'dark' || (darkMode === 'system' && window.matchMedia('(prefers-color-scheme: dark)').matches)}"
>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta charset="utf-8" />
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="white" />
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="black" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>embedding_representation_learning package | Corerec 0.2.3 documentation</title>
    <meta property="og:title" content="embedding_representation_learning package | Corerec 0.2.3 documentation" />
    <meta name="twitter:title" content="embedding_representation_learning package | Corerec 0.2.3 documentation" />
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8d216cef" />
      <link rel="stylesheet" type="text/css" href="_static/theme.css?v=edd7d3d2" />
        <link rel="search" title="Search" href="search.html" />
        <link rel="index" title="Index" href="genindex.html" />

    <script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
  <body x-data="{ showSidebar: false, showScrollTop: false }" class="min-h-screen font-sans antialiased bg-background text-foreground" :class="{ 'overflow-hidden': showSidebar }">
    <div x-cloak x-show="showSidebar" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm md:hidden" @click.self="showSidebar = false"></div><div id="page" class="relative flex flex-col min-h-screen"><a href="#content" class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100">
      Skip to content
    </a><header
  class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
    <div class="hidden mr-4 md:flex">
      <a href="index.html" class="flex items-center mr-6">
          <img width="24" height="24" class="mr-2 hidden dark:block" src="_static/drk.png" alt="Logo" />
        <img width="24" height="24" class="mr-2 dark:hidden" src="_static/lgt.png" alt="Logo" /><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">Corerec 0.2.3 documentation</span>
      </a></div><button
      class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden"
      type="button" @click="showSidebar = true">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" aria-hidden="true"
        fill="currentColor">
        <path
          d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z" />
      </svg>
      <span class="sr-only">Toggle navigation menu</span>
    </button>
    <div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
      <div class="flex-1 w-full md:w-auto md:flex-none"><form id="searchbox"
      action="search.html"
      method="get"
      class="relative flex items-center group"
      @keydown.k.window.meta="$refs.search.focus()">
  <input x-ref="search"
          name="q"
          id="search-input"
          type="search"
          aria-label="Search the docs"
          placeholder="Search ..."
          class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" />
  <kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
    <span class="text-xs">⌘</span>
    K
  </kbd>
</form>
      </div>
      <nav class="flex items-center space-x-1">
        <button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'"
          class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9"
          type="button"
          aria-label="Color theme switcher">
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0">
            <path
              d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z" />
          </svg>
          <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
            class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100">
            <path
              d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z" />
          </svg>
        </button>
      </nav>
    </div>
  </div>
</header>

    <div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside id="left-sidebar"
  class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky"
  :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }">

    <a href="index.html" class="!justify-start text-sm md:!hidden bg-background">
        <img width="16" height="16" class="mr-2 hidden dark:block" src="_static/drk.png" alt="Logo" />
        <img width="16" height="16" class="mr-2 dark:hidden" src="_static/lgt.png" alt="Logo" /><span class="font-bold text-clip whitespace-nowrap">Corerec 0.2.3 documentation</span>
    </a>

    <div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
      <div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
  
</nav>
      </div>
    </div>
    <button type="button" @click="showSidebar = false"
      class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100">
      <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 96 960 960" fill="currentColor"
        stroke="none" class="h-4 w-4">
        <path
          d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z" />
      </svg>
    </button>
  </aside>
        <main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs"
     class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
  <a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground"
     href="index.html">
    <span class="hidden md:inline">Corerec 0.2.3 documentation</span>
    <svg xmlns="http://www.w3.org/2000/svg"
         height="18"
         width="18"
         viewBox="0 96 960 960"
         aria-label="Home"
         fill="currentColor"
         stroke="none"
         class="md:hidden">
      <path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z" />
    </svg>
  </a>
  
<div class="mr-1">/</div><span aria-current="page"
        class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">embedding_representation_learning package</span>
</nav>

    <div id="content" role="main">
      <section id="embedding-representation-learning-package">
<h1>embedding_representation_learning package<a class="headerlink" href="#embedding-representation-learning-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
</section>
<section id="module-embedding_representation_learning.doc2vec">
<span id="embedding-representation-learning-doc2vec-module"></span><h2>embedding_representation_learning.doc2vec module<a class="headerlink" href="#module-embedding_representation_learning.doc2vec" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="embedding_representation_learning.doc2vec.DOC2VEC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">embedding_representation_learning.doc2vec.</span></span><span class="sig-name descname"><span class="pre">DOC2VEC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vector_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/doc2vec.html#DOC2VEC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.doc2vec.DOC2VEC" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A Doc2Vec model implementation for generating document embeddings.</p>
<p>This class provides methods for training document embeddings, retrieving vectors,
and managing model persistence. It’s particularly useful for recommendation systems
that need to understand document-level semantics.</p>
<dl class="simple">
<dt>Attributes:</dt><dd><p>model (Doc2Vec): The underlying Gensim Doc2Vec model instance</p>
</dd>
<dt>Methods:</dt><dd><p>train: Trains the Doc2Vec model on a corpus of documents
get_embedding: Retrieves the embedding vector for a specific document
save_model: Persists the trained model to disk
load_model: Loads a previously trained model from disk</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.doc2vec.DOC2VEC.get_embedding">
<span class="sig-name descname"><span class="pre">get_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/embedding_representation_learning/doc2vec.html#DOC2VEC.get_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.doc2vec.DOC2VEC.get_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Retrieve the embedding vector for a specific document.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>doc_id (int): The unique identifier of the document to embed.</dt><dd><p>Must be within range of trained documents.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>List[float]: A dense vector representation of the document with</dt><dd><p>dimensionality specified by vector_size.</p>
</dd>
</dl>
</dd>
<dt>Raises:</dt><dd><p>KeyError: If doc_id is not found in the trained model
RuntimeError: If called before training the model</p>
</dd>
<dt>Note:</dt><dd><p>The returned vector captures semantic properties of the document
and can be used for similarity calculations or as features for
downstream tasks.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.doc2vec.DOC2VEC.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/doc2vec.html#DOC2VEC.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.doc2vec.DOC2VEC.load_model" title="Link to this definition">¶</a></dt>
<dd><p>Load a pre-trained Doc2Vec model.</p>
<p>Parameters:
- path (str): File path of the saved model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.doc2vec.DOC2VEC.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/doc2vec.html#DOC2VEC.save_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.doc2vec.DOC2VEC.save_model" title="Link to this definition">¶</a></dt>
<dd><p>Save the trained Doc2Vec model.</p>
<p>Parameters:
- path (str): File path to save the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.doc2vec.DOC2VEC.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">documents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/doc2vec.html#DOC2VEC.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.doc2vec.DOC2VEC.train" title="Link to this definition">¶</a></dt>
<dd><p>Train the Doc2Vec model on a corpus of documents.</p>
<p>This method processes the input documents, builds a vocabulary, and trains
the model using the specified parameters from initialization.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>documents (List[List[str]]): A list of tokenized documents where each document</dt><dd><p>is represented as a list of strings (tokens).</p>
</dd>
</dl>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><code><span id="line-1"><span class="gp">&gt;&gt;&gt; </span><span class="n">doc2vec</span> <span class="o">=</span> <span class="n">DOC2VEC</span><span class="p">()</span>
</span><span id="line-2"><span class="gp">&gt;&gt;&gt; </span><span class="n">docs</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;this&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;doc1&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;this&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;doc2&#39;</span><span class="p">]]</span>
</span><span id="line-3"><span class="gp">&gt;&gt;&gt; </span><span class="n">doc2vec</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</span></code></pre></div>
</div>
</dd>
<dt>Note:</dt><dd><ul class="simple">
<li><p>Documents should be preprocessed (tokenized, cleaned) before training</p></li>
<li><p>Training time scales with corpus size and vector_size</p></li>
<li><p>Progress can be monitored through Gensim’s logging</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-embedding_representation_learning.personalized_embeddings">
<span id="embedding-representation-learning-personalized-embeddings-module"></span><h2>embedding_representation_learning.personalized_embeddings module<a class="headerlink" href="#module-embedding_representation_learning.personalized_embeddings" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">embedding_representation_learning.personalized_embeddings.</span></span><span class="sig-name descname"><span class="pre">PERSONALIZED_EMBEDDINGS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word2vec_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doc2vec_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A unified embedding manager combining Word2Vec and Doc2Vec capabilities.</p>
<p>This class provides a comprehensive interface for training and managing both word
and document embeddings, making it suitable for personalized recommendation systems
that need to understand both word-level and document-level semantics.</p>
<dl class="simple">
<dt>Attributes:</dt><dd><p>word2vec (WORD2VEC): Instance of the Word2Vec model for word embeddings
doc2vec (DOC2VEC): Instance of the Doc2Vec model for document embeddings</p>
</dd>
<dt>Methods:</dt><dd><p>train_word2vec: Trains the Word2Vec model on a corpus of sentences
train_doc2vec: Trains the Doc2Vec model on a corpus of documents
get_word_embedding: Retrieves word vectors
get_doc_embedding: Retrieves document vectors
save_models: Persists both models to disk
load_models: Loads both models from disk</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_doc_embedding">
<span class="sig-name descname"><span class="pre">get_doc_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">doc_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.get_doc_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_doc_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Get the embedding vector for a given document ID.</p>
<p>Parameters:
- doc_id (int): The document ID.</p>
<p>Returns:
- List[float]: The embedding vector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_word_embedding">
<span class="sig-name descname"><span class="pre">get_word_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.get_word_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_word_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Get the embedding vector for a given word.</p>
<p>Parameters:
- word (str): The word to retrieve the embedding for.</p>
<p>Returns:
- List[float]: The embedding vector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.load_models">
<span class="sig-name descname"><span class="pre">load_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word2vec_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doc2vec_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.load_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.load_models" title="Link to this definition">¶</a></dt>
<dd><p>Load pre-trained Word2Vec and Doc2Vec models.</p>
<p>Parameters:
- word2vec_path (str): File path of the saved Word2Vec model.
- doc2vec_path (str): File path of the saved Doc2Vec model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.save_models">
<span class="sig-name descname"><span class="pre">save_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word2vec_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doc2vec_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.save_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.save_models" title="Link to this definition">¶</a></dt>
<dd><p>Save both Word2Vec and Doc2Vec models.</p>
<p>Parameters:
- word2vec_path (str): File path to save the Word2Vec model.
- doc2vec_path (str): File path to save the Doc2Vec model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_doc2vec">
<span class="sig-name descname"><span class="pre">train_doc2vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">documents</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.train_doc2vec"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_doc2vec" title="Link to this definition">¶</a></dt>
<dd><p>Train the Doc2Vec model.</p>
<p>Parameters:
- documents (List[List[str]]): A list of tokenized documents.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_word2vec">
<span class="sig-name descname"><span class="pre">train_word2vec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/personalized_embeddings.html#PERSONALIZED_EMBEDDINGS.train_word2vec"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_word2vec" title="Link to this definition">¶</a></dt>
<dd><p>Train the Word2Vec model.</p>
<p>Parameters:
- sentences (List[List[str]]): A list of tokenized sentences.
- epochs (int): Number of training iterations.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-embedding_representation_learning.word2vec">
<span id="embedding-representation-learning-word2vec-module"></span><h2>embedding_representation_learning.word2vec module<a class="headerlink" href="#module-embedding_representation_learning.word2vec" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="embedding_representation_learning.word2vec.WORD2VEC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">embedding_representation_learning.word2vec.</span></span><span class="sig-name descname"><span class="pre">WORD2VEC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vector_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/word2vec.html#WORD2VEC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.word2vec.WORD2VEC" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A Word2Vec model implementation for generating word embeddings.</p>
<p>This class provides methods for training word embeddings and managing model
persistence. It’s particularly useful for recommendation systems that need
to understand word-level semantics.</p>
<dl class="simple">
<dt>Attributes:</dt><dd><p>model (Word2Vec): The underlying Gensim Word2Vec model instance</p>
</dd>
<dt>Methods:</dt><dd><p>train: Trains the Word2Vec model on a corpus of sentences
get_embedding: Retrieves the embedding vector for a specific word
save_model: Persists the trained model to disk
load_model: Loads a previously trained model from disk</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.word2vec.WORD2VEC.get_embedding">
<span class="sig-name descname"><span class="pre">get_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">word</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/embedding_representation_learning/word2vec.html#WORD2VEC.get_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.word2vec.WORD2VEC.get_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Get the embedding vector for a given word.</p>
<p>Parameters:
- word (str): The word to retrieve the embedding for.</p>
<p>Returns:
- List[float]: The embedding vector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.word2vec.WORD2VEC.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/word2vec.html#WORD2VEC.load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.word2vec.WORD2VEC.load_model" title="Link to this definition">¶</a></dt>
<dd><p>Load a pre-trained Word2Vec model.</p>
<p>Parameters:
- path (str): File path of the saved model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.word2vec.WORD2VEC.save_model">
<span class="sig-name descname"><span class="pre">save_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/word2vec.html#WORD2VEC.save_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.word2vec.WORD2VEC.save_model" title="Link to this definition">¶</a></dt>
<dd><p>Save the trained Word2Vec model.</p>
<p>Parameters:
- path (str): File path to save the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="embedding_representation_learning.word2vec.WORD2VEC.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/embedding_representation_learning/word2vec.html#WORD2VEC.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#embedding_representation_learning.word2vec.WORD2VEC.train" title="Link to this definition">¶</a></dt>
<dd><p>Train the Word2Vec model on a corpus of sentences.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>sentences (List[List[str]]): A list of tokenized sentences where each sentence</dt><dd><p>is represented as a list of strings (tokens).</p>
</dd>
<dt>epochs (int): Number of iterations over the corpus during training.</dt><dd><p>More epochs can improve quality but increase training time.</p>
</dd>
</dl>
</dd>
<dt>Note:</dt><dd><ul class="simple">
<li><p>Sentences should be preprocessed (tokenized, cleaned) before training</p></li>
<li><p>Training time scales with corpus size and vector_size</p></li>
<li><p>Progress can be monitored through Gensim’s logging</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-embedding_representation_learning">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-embedding_representation_learning" title="Link to this heading">¶</a></h2>
</section>
</section>

    </div></div><aside id="right-sidebar" class="hidden text-sm xl:block">
  <div class="sticky top-16 -mt-10 max-h-[calc(100vh-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
    <ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-embedding_representation_learning.doc2vec">embedding_representation_learning.doc2vec module</a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.doc2vec.DOC2VEC"><code class="docutils literal notranslate"><span class="pre">DOC2VEC</span></code></a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.doc2vec.DOC2VEC.get_embedding"><code class="docutils literal notranslate"><span class="pre">DOC2VEC.get_embedding()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.doc2vec.DOC2VEC.load_model"><code class="docutils literal notranslate"><span class="pre">DOC2VEC.load_model()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.doc2vec.DOC2VEC.save_model"><code class="docutils literal notranslate"><span class="pre">DOC2VEC.save_model()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.doc2vec.DOC2VEC.train"><code class="docutils literal notranslate"><span class="pre">DOC2VEC.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-embedding_representation_learning.personalized_embeddings">embedding_representation_learning.personalized_embeddings module</a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS</span></code></a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_doc_embedding"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.get_doc_embedding()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.get_word_embedding"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.get_word_embedding()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.load_models"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.load_models()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.save_models"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.save_models()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_doc2vec"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.train_doc2vec()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.personalized_embeddings.PERSONALIZED_EMBEDDINGS.train_word2vec"><code class="docutils literal notranslate"><span class="pre">PERSONALIZED_EMBEDDINGS.train_word2vec()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-embedding_representation_learning.word2vec">embedding_representation_learning.word2vec module</a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.word2vec.WORD2VEC"><code class="docutils literal notranslate"><span class="pre">WORD2VEC</span></code></a><ul>
<li><a class="reference internal" href="#embedding_representation_learning.word2vec.WORD2VEC.get_embedding"><code class="docutils literal notranslate"><span class="pre">WORD2VEC.get_embedding()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.word2vec.WORD2VEC.load_model"><code class="docutils literal notranslate"><span class="pre">WORD2VEC.load_model()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.word2vec.WORD2VEC.save_model"><code class="docutils literal notranslate"><span class="pre">WORD2VEC.save_model()</span></code></a></li>
<li><a class="reference internal" href="#embedding_representation_learning.word2vec.WORD2VEC.train"><code class="docutils literal notranslate"><span class="pre">WORD2VEC.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-embedding_representation_learning">Module contents</a></li>
</ul>
</div>
</aside>
        </main>
      </div>
    </div><footer class="py-6 border-t border-border md:py-0">
    <div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
      <div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
        <p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2024, Vishesh Yadav&nbsp;Built with <a class="font-medium underline underline-offset-4"
    href="https://www.sphinx-doc.org"
    rel="noreferrer">Sphinx 8.1.3</a></p>
</div>
</div>
</footer>
  </div>
  
    <script src="_static/documentation_options.js?v=a47416a6"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script defer="defer" src="_static/theme.js?v=1808ab49"></script>
  
</body>
</html>